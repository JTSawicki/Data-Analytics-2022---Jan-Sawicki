{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmdstanpy import CmdStanModel\n",
    "\n",
    "\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate fake data, that will simulate dataset of 100 outputs from 200 dimensional linear model along with appropriate predictors. Our goal will be estimation of the parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cmdstanpy:found newer exe file, not recompiling\n"
     ]
    }
   ],
   "source": [
    "data_genetator = CmdStanModel(stan_file = 'generate_data.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cmdstanpy:CmdStan start procesing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19990307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chain 1 |\u001b[34m██████████\u001b[0m| 00:00 Sampling completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:cmdstanpy:CmdStan done processing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "I= 3 #number of letters in name\n",
    "N= 7 #number of letters in surname\n",
    "DoB= 1999 #date of birth\n",
    "seed=int(DoB*1e4+100*I+N)\n",
    "print(seed)\n",
    "generated_data = data_genetator.sample(chains=1, iter_sampling=1, iter_warmup=0, fixed_param=True,seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients of linear model\n",
    "Only few of beta coefficients are significantly greater than 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.patches.StepPatch at 0x201a106cb20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta_s = generated_data.stan_variable('beta')\n",
    "plt.stairs(generated_data.stan_variable('beta')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an issue called sparsity. We will try to exploit that when infering the results via changing the prior structure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - uniform prior for beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cmdstanpy:found newer exe file, not recompiling\n"
     ]
    }
   ],
   "source": [
    "model_uniform = CmdStanModel(stan_file = 'model1.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_inference = {'N':100,\n",
    "                      'M':200,\n",
    "                      'X':generated_data.stan_variable('X')[0],\n",
    "                      'y':generated_data.stan_variable('y')[0]\n",
    "                      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cmdstanpy:CmdStan start procesing\n",
      "chain 1 |\u001b[33m          \u001b[0m| 00:00 Status\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m▉         \u001b[0m| 00:02 Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "\n",
      "chain 1 |\u001b[33m█▎        \u001b[0m| 00:04 Iteration:  100 / 2000 [  5%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m█▊        \u001b[0m| 00:07 Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m██▎       \u001b[0m| 00:10 Iteration:  300 / 2000 [ 15%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m██▋       \u001b[0m| 00:12 Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m███▏      \u001b[0m| 00:15 Iteration:  500 / 2000 [ 25%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m███▋      \u001b[0m| 00:18 Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m████      \u001b[0m| 00:20 Iteration:  700 / 2000 [ 35%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m████▌     \u001b[0m| 00:23 Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m█████     \u001b[0m| 00:26 Iteration:  900 / 2000 [ 45%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[34m█████▉    \u001b[0m| 00:29 Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[34m██████▎   \u001b[0m| 00:32 Iteration: 1100 / 2000 [ 55%]  (Sampling)\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[34m██████▊   \u001b[0m| 00:34 Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[34m███████▎  \u001b[0m| 00:37 Iteration: 1300 / 2000 [ 65%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[34m███████▋  \u001b[0m| 00:40 Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "fit_unf = model_uniform.sample(data=data_for_inference,seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_unf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing csv files: C:\\Users\\jasio\\AppData\\Local\\Temp\\tmp0qbg5z38\\model1-20220329101634_1.csv, C:\\Users\\jasio\\AppData\\Local\\Temp\\tmp0qbg5z38\\model1-20220329101634_2.csv, C:\\Users\\jasio\\AppData\\Local\\Temp\\tmp0qbg5z38\\model1-20220329101634_3.csv, C:\\Users\\jasio\\AppData\\Local\\Temp\\tmp0qbg5z38\\model1-20220329101634_4.csv\n",
      "\n",
      "Checking sampler transitions treedepth.\n",
      "3964 of 4000 (99.10%) transitions hit the maximum treedepth limit of 10, or 2^10 leapfrog steps.\n",
      "Trajectories that are prematurely terminated due to this limit will result in slow exploration.\n",
      "For optimal performance, increase this limit.\n",
      "\n",
      "Checking sampler transitions for divergences.\n",
      "36 of 4000 (0.90%) transitions ended with a divergence.\n",
      "These divergent transitions indicate that HMC is not fully able to explore the posterior distribution.\n",
      "Try increasing adapt delta closer to 1.\n",
      "If this doesn't remove all divergences, try to reparameterize the model.\n",
      "\n",
      "Checking E-BFMI - sampler transitions HMC potential energy.\n",
      "The E-BFMI, 0.08, is below the nominal threshold of 0.30 which suggests that HMC may have trouble exploring the target distribution.\n",
      "If possible, try to reparameterize the model.\n",
      "\n",
      "The following parameters had fewer than 0.001 effective draws per transition:\n",
      "  beta[2], beta[3], beta[4], beta[5], beta[6], beta[7], beta[8], beta[9], beta[10], beta[11], beta[12], beta[13], beta[14], beta[15], beta[16], beta[17], beta[18], beta[19], beta[20], beta[21], beta[22], beta[24], beta[25], beta[26], beta[28], beta[29], beta[30], beta[31], beta[32], beta[33], beta[34], beta[35], beta[36], beta[37], beta[38], beta[39], beta[40], beta[41], beta[42], beta[43], beta[44], beta[46], beta[47], beta[48], beta[49], beta[50], beta[51], beta[52], beta[53], beta[54], beta[55], beta[56], beta[57], beta[59], beta[60], beta[61], beta[62], beta[63], beta[64], beta[65], beta[66], beta[67], beta[68], beta[69], beta[70], beta[71], beta[72], beta[73], beta[74], beta[75], beta[76], beta[77], beta[78], beta[79], beta[80], beta[81], beta[82], beta[83], beta[84], beta[85], beta[86], beta[87], beta[88], beta[89], beta[90], beta[92], beta[93], beta[94], beta[95], beta[96], beta[97], beta[98], beta[99], beta[100], beta[102], beta[103], beta[104], beta[105], beta[106], beta[108], beta[109], beta[111], beta[112], beta[113], beta[114], beta[115], beta[117], beta[118], beta[119], beta[120], beta[121], beta[122], beta[123], beta[124], beta[125], beta[126], beta[127], beta[128], beta[129], beta[130], beta[131], beta[132], beta[133], beta[134], beta[135], beta[136], beta[137], beta[138], beta[139], beta[141], beta[142], beta[143], beta[144], beta[145], beta[146], beta[147], beta[148], beta[149], beta[150], beta[151], beta[152], beta[153], beta[154], beta[155], beta[157], beta[158], beta[159], beta[160], beta[161], beta[162], beta[163], beta[165], beta[166], beta[167], beta[168], beta[169], beta[170], beta[171], beta[172], beta[173], beta[174], beta[175], beta[176], beta[178], beta[179], beta[180], beta[181], beta[182], beta[183], beta[184], beta[185], beta[186], beta[187], beta[188], beta[189], beta[190], beta[191], beta[192], beta[193], beta[194], beta[195], beta[196], beta[197], beta[198], beta[199], beta[200], sigma\n",
      "Such low values indicate that the effective sample size estimators may be biased high and actual performance may be substantially lower than quoted.\n",
      "\n",
      "The following parameters had split R-hat greater than 1.05:\n",
      "  beta[1], beta[2], beta[3], beta[4], beta[5], beta[6], beta[7], beta[8], beta[9], beta[10], beta[11], beta[12], beta[13], beta[14], beta[15], beta[16], beta[17], beta[18], beta[19], beta[20], beta[21], beta[22], beta[23], beta[24], beta[25], beta[26], beta[27], beta[28], beta[29], beta[30], beta[31], beta[32], beta[33], beta[34], beta[35], beta[36], beta[37], beta[38], beta[39], beta[40], beta[41], beta[42], beta[43], beta[44], beta[45], beta[46], beta[47], beta[48], beta[49], beta[50], beta[51], beta[52], beta[53], beta[54], beta[55], beta[56], beta[57], beta[58], beta[59], beta[60], beta[61], beta[62], beta[63], beta[64], beta[65], beta[66], beta[67], beta[68], beta[69], beta[70], beta[71], beta[72], beta[73], beta[74], beta[75], beta[76], beta[77], beta[78], beta[79], beta[80], beta[81], beta[82], beta[83], beta[84], beta[85], beta[86], beta[87], beta[88], beta[89], beta[90], beta[91], beta[92], beta[93], beta[94], beta[95], beta[96], beta[97], beta[98], beta[99], beta[100], beta[101], beta[102], beta[103], beta[104], beta[105], beta[106], beta[107], beta[108], beta[109], beta[110], beta[111], beta[112], beta[113], beta[114], beta[115], beta[116], beta[117], beta[118], beta[119], beta[120], beta[121], beta[122], beta[123], beta[124], beta[125], beta[126], beta[127], beta[128], beta[129], beta[130], beta[131], beta[132], beta[133], beta[134], beta[135], beta[136], beta[137], beta[138], beta[139], beta[140], beta[141], beta[142], beta[143], beta[144], beta[145], beta[146], beta[147], beta[148], beta[149], beta[150], beta[151], beta[152], beta[153], beta[154], beta[155], beta[156], beta[157], beta[158], beta[159], beta[160], beta[161], beta[162], beta[163], beta[164], beta[165], beta[166], beta[167], beta[168], beta[169], beta[170], beta[171], beta[172], beta[173], beta[174], beta[175], beta[176], beta[177], beta[178], beta[179], beta[180], beta[181], beta[182], beta[183], beta[184], beta[185], beta[186], beta[187], beta[188], beta[189], beta[190], beta[191], beta[192], beta[193], beta[194], beta[195], beta[196], beta[197], beta[198], beta[199], beta[200], alpha, sigma\n",
      "Such high values indicate incomplete mixing and biased estimation.\n",
      "You should consider regularizating your model with additional prior information or a more effective parameterization.\n",
      "\n",
      "Processing complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fit_unf.diagnose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1. Evaluating model\n",
    "\n",
    "1. Analyse the diagnosis of model. What sampling issues occured?\n",
    "2. For each fitted beta coefficient plot maximum, minimum, and 5, 25, 50, 75, 95 quantiles of simulated weight (all in the same plot). Compare with true values of beta. \n",
    "3. Substract true values from fitted betas and make the same plot (residues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - Narrow weakly informative prior.\n",
    "We try to improve sampling by regularizing the search space with normal priors. This is prior used in ridge regression (but here is the bayesian context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cmdstanpy:compiling stan file C:\\Users\\jasio\\Desktop\\GitHub\\Data-Analytics-2022---Jan-Sawicki\\Labolatory 04\\model2.stan to exe file C:\\Users\\jasio\\Desktop\\GitHub\\Data-Analytics-2022---Jan-Sawicki\\Labolatory 04\\model2.exe\n",
      "INFO:cmdstanpy:compiled model executable: C:\\Users\\jasio\\Desktop\\GitHub\\Data-Analytics-2022---Jan-Sawicki\\Labolatory 04\\model2.exe\n"
     ]
    }
   ],
   "source": [
    "model_reg = CmdStanModel(stan_file = 'model2.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cmdstanpy:CmdStan start procesing\n",
      "chain 1 |\u001b[33m          \u001b[0m| 00:00 Status\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m▉         \u001b[0m| 00:01 Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m█▎        \u001b[0m| 00:01 Iteration:  100 / 2000 [  5%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m█▊        \u001b[0m| 00:02 Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m██▎       \u001b[0m| 00:02 Iteration:  300 / 2000 [ 15%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m██▋       \u001b[0m| 00:03 Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m███▏      \u001b[0m| 00:03 Iteration:  500 / 2000 [ 25%]  (Warmup)\n",
      "chain 1 |\u001b[33m███▋      \u001b[0m| 00:03 Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m████      \u001b[0m| 00:04 Iteration:  700 / 2000 [ 35%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m████▌     \u001b[0m| 00:04 Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m█████     \u001b[0m| 00:04 Iteration:  900 / 2000 [ 45%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[34m█████▉    \u001b[0m| 00:05 Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[34m██████▎   \u001b[0m| 00:05 Iteration: 1100 / 2000 [ 55%]  (Sampling)\n",
      "\n",
      "chain 1 |\u001b[34m██████▊   \u001b[0m| 00:06 Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[34m███████▎  \u001b[0m| 00:06 Iteration: 1300 / 2000 [ 65%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[34m███████▋  \u001b[0m| 00:07 Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[34m████████▏ \u001b[0m| 00:07 Iteration: 1500 / 2000 [ 75%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[34m████████▋ \u001b[0m| 00:08 Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "\n",
      "chain 1 |\u001b[34m█████████ \u001b[0m| 00:08 Iteration: 1700 / 2000 [ 85%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[34m█████████▌\u001b[0m| 00:09 Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[34m██████████\u001b[0m| 00:09 Iteration: 1900 / 2000 [ 95%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "chain 1 |\u001b[34m██████████\u001b[0m| 00:11 Sampling completed                       \n",
      "chain 2 |\u001b[34m██████████\u001b[0m| 00:11 Sampling completed                       \n",
      "chain 3 |\u001b[34m██████████\u001b[0m| 00:11 Sampling completed                       \n",
      "chain 4 |\u001b[34m██████████\u001b[0m| 00:11 Sampling completed                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:cmdstanpy:CmdStan done processing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fit_reg = model_reg.sample(data=data_for_inference,seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing csv files: C:\\Users\\jasio\\AppData\\Local\\Temp\\tmp0qbg5z38\\model2-20220329102357_1.csv, C:\\Users\\jasio\\AppData\\Local\\Temp\\tmp0qbg5z38\\model2-20220329102357_2.csv, C:\\Users\\jasio\\AppData\\Local\\Temp\\tmp0qbg5z38\\model2-20220329102357_3.csv, C:\\Users\\jasio\\AppData\\Local\\Temp\\tmp0qbg5z38\\model2-20220329102357_4.csv\n",
      "\n",
      "Checking sampler transitions treedepth.\n",
      "Treedepth satisfactory for all transitions.\n",
      "\n",
      "Checking sampler transitions for divergences.\n",
      "No divergent transitions found.\n",
      "\n",
      "Checking E-BFMI - sampler transitions HMC potential energy.\n",
      "E-BFMI satisfactory.\n",
      "\n",
      "Effective sample size satisfactory.\n",
      "\n",
      "Split R-hat values satisfactory all parameters.\n",
      "\n",
      "Processing complete, no problems detected.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fit_reg.diagnose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2. Evaluating model\n",
    "\n",
    "1. Analyse the diagnosis of model. Are the sampling problems solved\n",
    "2. For each fitted beta coefficient plot maximum, minimum, and 5, 25, 50, 75, 95 quantiles of simulated weight (all in the same plot). Compare with true values of beta. \n",
    "3. Substract true values from fitted betas and make the same plot (residues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 -  Sparsity enforcing prior\n",
    "\n",
    "We will now try to enforce shrinking of small parameters using a Laplace prior. This is a prior that is used in Lasso regression. (but here is the bayesian context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cmdstanpy:compiling stan file C:\\Users\\jasio\\Desktop\\GitHub\\Data-Analytics-2022---Jan-Sawicki\\Labolatory 04\\model3.stan to exe file C:\\Users\\jasio\\Desktop\\GitHub\\Data-Analytics-2022---Jan-Sawicki\\Labolatory 04\\model3.exe\n",
      "INFO:cmdstanpy:compiled model executable: C:\\Users\\jasio\\Desktop\\GitHub\\Data-Analytics-2022---Jan-Sawicki\\Labolatory 04\\model3.exe\n"
     ]
    }
   ],
   "source": [
    "model_lap = CmdStanModel(stan_file = 'model3.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cmdstanpy:CmdStan start procesing\n",
      "chain 1 |\u001b[33m          \u001b[0m| 00:00 Status\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m▍         \u001b[0m| 00:00 Status\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m▉         \u001b[0m| 00:10 Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m█▎        \u001b[0m| 00:22 Iteration:  100 / 2000 [  5%]  (Warmup)\n",
      "\n",
      "chain 1 |\u001b[33m█▊        \u001b[0m| 00:32 Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m██▎       \u001b[0m| 00:44 Iteration:  300 / 2000 [ 15%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m██▋       \u001b[0m| 01:00 Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m███▏      \u001b[0m| 01:19 Iteration:  500 / 2000 [ 25%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m███▋      \u001b[0m| 01:45 Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m████      \u001b[0m| 02:13 Iteration:  700 / 2000 [ 35%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m████▌     \u001b[0m| 02:42 Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[34m█████▉    \u001b[0m| 03:09 Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[34m██████▊   \u001b[0m| 03:32 Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[34m███████▎  \u001b[0m| 03:42 Iteration: 1300 / 2000 [ 65%]  (Sampling)\n",
      "\n",
      "chain 1 |\u001b[34m████████▏ \u001b[0m| 04:04 Iteration: 1500 / 2000 [ 75%]  (Sampling)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[34m█████████ \u001b[0m| 04:24 Iteration: 1700 / 2000 [ 85%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[34m█████████▌\u001b[0m| 04:35 Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "\n",
      "chain 1 |\u001b[34m██████████\u001b[0m| 04:46 Iteration: 1900 / 2000 [ 95%]  (Sampling)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "fit_lap = model_lap.sample(data=data_for_inference,seed=seed,adapt_delta=0.99,max_treedepth=12) #sampling problematic some parameters have to be adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit_lap.diagnose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3. Evaluating model\n",
    "\n",
    "1. Analyse the diagnosis of model. Are the sampling problems solved. Are there any new sampling issues?\n",
    "2. For each fitted beta coefficient plot maximum, minimum, and 5, 25, 50, 75, 95 quantiles of simulated weight (all in the same plot). Compare with true values of beta. \n",
    "3. Substract true values from fitted betas and make the same plot (residues)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21d2c9d8169a72a6ee8a47ec19871551033632d248d241d399f03ea8178d894d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
